{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Lightning Introduction\n",
    "\n",
    "Welcome to the introduction to [`PyTorchLightning`](https://www.pytorchlightning.ai/). PyTorch Lightning is a wrapper for PyTorch that is focused towards building neural networks model quickly by removing the boilerplate code. It also extends the functionality of PyTorch, for example, with model Callbacks and automatic porting to GPU to accelerate computations.\n",
    "\n",
    "In its essence, pytorch lightning provides a controlled setup where you are forced to in its specific partly automated library setup, but are able to customize/de-automatate each process if you so desire. You can both rely on a variety of already implemented functionalities and the fact that your code is by definition structured clearly, but at the cost of having to delve into their code structure and figuring out which functions to use.\n",
    "\n",
    "Our suggestion is to try it out. If you like it, cool, otherwise you can just stick to pytorch and build up your own library of functions you will use throughout your Deep Learning journey.\n",
    "\n",
    "Let's get started by installing PyTorch Lightning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Mount folder in Colab\n",
    "\n",
    "Uncomment thefollowing cell to mount your gdrive if you are using the notebook in google colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "gdrive_path='/content/gdrive/MyDrive/i2dl/exercise_07'\n",
    "\n",
    "# This will mount your google drive under 'MyDrive'\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "# In order to access the files in this notebook we have to navigate to the correct folder\n",
    "os.chdir(gdrive_path)\n",
    "# Check manually if all files are present\n",
    "print(sorted(os.listdir()))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: install correct libraries in google colab\n",
    "# !python -m pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !python -m pip install torchtext==0.12.0 torchaudio==0.11.0\n",
    "# !python -m pip install tensorboard==2.9.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For automatic file reloading as usual\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# For google colab\n",
    "# !python -m pip install pytorch-lightning==1.6.0 > /dev/null\n",
    "\n",
    "# For anaconda/regular python\n",
    "# !{sys.executable} -m pip install pytorch-lightning==1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lightning version: 1.6.0\n",
      "Tensorboard version: 2.9.1\n",
      "PyTorch version Installed: 1.11.0+cu113\n",
      "Torchvision version Installed: 0.12.0+cu113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "print(f\"Lightning version: {pl.__version__}\")\n",
    "if not pl.__version__.startswith(\"1.6\"):\n",
    "    print(\"You are using another version of pytorch lightning. We expect pytorch lightning 1.6.0. You can continue with your version but it\"\n",
    "          \" might cause dependency and compatibility issues.\")\n",
    "\n",
    "import tensorboard\n",
    "import torch\n",
    "import torchvision\n",
    "print(f\"Tensorboard version: {tensorboard.__version__}\")\n",
    "if not tensorboard.__version__.startswith(\"2.9.1\"):\n",
    "    print(\"You are using an another version of Tensorboard. We expect Tensorboard 2.9.1 You may continue using your version but it\"\n",
    "          \" might cause dependency and compatibility issues.\")\n",
    "print(f\"PyTorch version Installed: {torch.__version__}\\nTorchvision version Installed: {torchvision.__version__}\\n\")\n",
    "if not torch.__version__.startswith(\"1.11\"):\n",
    "    print(\"you are using an another version of PyTorch. We expect PyTorch 1.11.0. You may continue using your version but it\"\n",
    "          \" might cause dependency and compatibility issues.\")\n",
    "if not torchvision.__version__.startswith(\"0.12\"):\n",
    "    print(\"you are using an another version of torchvision. We expect torchvision 0.12. You can continue with your version but it\"\n",
    "          \" might cause dependency and compatibility issues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Idea behind PyTorch Lightning\n",
    "\n",
    "Codes in a Deep learning project consists of three main categories:\n",
    "\n",
    "1. **Research code**   \n",
    "    This is the exciting part of the experiment where you configure the model architecture and try out different optimizers and target task. This is managed by the `LightningModule` of PyTorch Lightning.\n",
    "    \n",
    "2. **Engineering code**  \n",
    "    This is the same set of code that remain the same for all deep learning projects.Recall the training block of previous notebooks where we loop through the epochs and mini-batches. The `Trainer` class of PyTorch Lightning takes care of this part of code.\n",
    "    \n",
    "3. **Non-essential code**\n",
    "    It is very important that we log our training metrics and organize different training runs to have purposeful experimentation of models. The `Callbacks` class PyTorch Lightning helps us with this section. \n",
    "\n",
    "Let's look at each of these modules in detail.\n",
    "\n",
    "1. **LightningModules** contain all model related code. This is the part where we are working on when creating a new project. The idea is to have all important code in one module, e.g., the model's architecture and the evaluation of training and validation metrics. This provides a better overview as repeated elements, such as the training procedure, are not stored in the code that we work on. The lightning module also handles the calls `.to(device)` or `.train()` and `.eval()`. Hence, there is no need anymore to switch between the cpu and gpu and to take care of the model's mode as this is automated by the LightningModule. The framework also enables easy parallel computation on multiple gpus. \n",
    "\n",
    "2. **Trainer** contains all code needed for training our neural networks that doesn't change for each project (\"one size fits all\"). Usually, we don't touch the code automated by this class. The arguments that are specific for one training such as learning rate and batch size are provided as initialization arguments for the LightningModule.\n",
    "\n",
    "3. **Callbacks** automate all parts needed for logging hyperparameters or training results such as the tensorboard logger. Logging becomes very important for research later since the results of experiments need to be reproducible.\n",
    "\n",
    "All in all, PyTorch is a framework that handles all (annoying) \"engineering\" stuff for you such that you have more time for exciting research and scientific coding. This also results in the advantage that automated parts are guaranteed to be bug-free. Hence, you can't include a bug in a part of your code that is often used but not often checked. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Overview of the PyTorch Lightning code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research relevant code goes into the `LightningModule`. The advantage is that we have all the model building, training & validation steps within a single class. These are the components that usually change based on the projects and tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorBoard Interface](./images/pl_quick_start_full_compressed.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining code is automated by the `Trainer` class which takes care of the tasks of our mechanical training loops components such as iterating through the minibatches and gradient updating steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://miro.medium.com/max/700/1*b81_j__xv8M0Bb6nFTXbAA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could already see how much more readable and concise our code is, after being transformed by PyTorch Lightning.\n",
    "\n",
    "Let us now train a neural network model with PyTorch Lightning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training with PyTorch Lightning\n",
    "\n",
    "We will build a two-layer neural network to train on the the [`Fashion-MNIST`](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/) dataset for this notebook. \n",
    "\n",
    "## 3.1 Define A LightningModule\n",
    "\n",
    "We define our network as an instance of `pl.LightningModule` which replaces our `PyTorch` network based on the class `nn.Module`. Additionally, it contains all the relevant parts that are used for training and evaluating different models on various tasks.  \n",
    "\n",
    "Let's have a look at the implementation of `TwoLayerNet` in `exercise_code.lightning_models`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `__init__()` and `forward()` function defining the forward  pass remain the same. Hence, we can just copy the code from the `nn.Module`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class TwoLayerNet(pl.LightningModule):\n",
    "    def __init__(self, hparams, input_size=1 * 28 * 28, hidden_size=512, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(hparams)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten the image  before sending as input to the model\n",
    "        N, _, _, _ = x.shape\n",
    "        x = x.view(N, -1)\n",
    "\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define the training  and validation steps since they also vary with different tasks and projects. Consequently, it is useful to integrate these parts into our instance of `LightningModule`. Validation loss is returned for each validation mini-batch and averaged at the end of the epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "\n",
    "        # Perform a forward pass on the network with inputs\n",
    "        out = self.forward(images)\n",
    "\n",
    "        # calculate the loss with the network predictions and ground truth targets\n",
    "        loss = F.cross_entropy(out, targets)\n",
    "\n",
    "        # Find the predicted class from probabilities of the image belonging to each of the classes\n",
    "        # from the network output\n",
    "        _, preds = torch.max(out, 1)\n",
    "\n",
    "        # Calculate the accuracy of predictions\n",
    "        acc = preds.eq(targets).sum().float() / targets.size(0)\n",
    "\n",
    "        # Log the accuracy and loss values to the tensorboard\n",
    "        self.log('loss', loss)\n",
    "        self.log('acc', acc)\n",
    "\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "\n",
    "        # Perform a forward pass on the network with inputs\n",
    "        out = self.forward(images)\n",
    "\n",
    "        # calculate the loss with the network predictions and ground truth targets\n",
    "        loss = F.cross_entropy(out, targets)\n",
    "\n",
    "        # Find the predicted class from probabilities of the image belonging to each of the classes\n",
    "        # from the network output\n",
    "        _, preds = torch.max(out, 1)\n",
    "\n",
    "        # Calculate the accuracy of predictions\n",
    "        acc = preds.eq(targets).sum().float() / targets.size(0)\n",
    "\n",
    "        # Visualise the predictions  of the model\n",
    "        if batch_idx == 0:\n",
    "            self.visualize_predictions(images, out.detach(), targets)\n",
    "\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "\n",
    "        # Average the loss over the entire validation data from it's mini-batches\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "\n",
    "        # Log the validation accuracy and loss values to the tensorboard\n",
    "        self.log('val_loss', avg_loss)\n",
    "        self.log('val_acc', avg_acc)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step missing in our `LightningModule` is the optimizer. This method needs to be defined in every `LightningModule`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(self.model.parameters(), self.hparams[\"learning_rate\"], momentum=0.9)\n",
    "\n",
    "        return optim\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have set up the model and the training steps, we will now establish the data pipeline. PyTorch Lightning provides the `LightningDataModule` for setting up the dataloaders.\n",
    "\n",
    "Let's have a look at the implementation of `FashionMNISTDataModule` in `exercise_code.data_class`.\n",
    "\n",
    "The `prepare_data()` function intends to set up the dataset and the related transforms for it. As previously, we download the `FashionMNIST` dataset using `torchvision` and split the total training data into a training and validation set for tuning hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class FashionMNISTDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, batch_size=4):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def prepare_data(self):\n",
    "\n",
    "        # Define the transform\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "        # Download the Fashion-MNIST dataset\n",
    "        fashion_mnist_train_val = torchvision.datasets.FashionMNIST(root='../datasets', train=True,\n",
    "                                                                   download=True, transform=transform)\n",
    "\n",
    "        self.fashion_mnist_test = torchvision.datasets.FashionMNIST(root='../datasets', train=False,\n",
    "                                                                 download=True, transform=transform)\n",
    "\n",
    "        # Apply the Transforms\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "        # Perform the training and validation split\n",
    "        self.train_dataset, self.val_dataset = random_split(\n",
    "            fashion_mnist_train_val, [50000, 10000])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall now define `Dataloaders` for each of the data-splits. These data loaders can be directly called during model training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.fashion_mnist_test, batch_size=self.batch_size)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can notice now that most of the code of these steps can be directly copied from a Vanilla PyTorch code. Lightning just rearranges them. This marks the end of the research part of the code.\n",
    "\n",
    "Let's see now how the `Trainer` class works:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.2 Fitting the model with a Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will initialize the model and the data  with a set of hyperparameters given in the dictionary `hparams`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output \n",
    "\n",
    "from exercise_code.lightning_models import TwoLayerNet\n",
    "from exercise_code.data_class import FashionMNISTDataModule\n",
    "\n",
    "hparams = {\n",
    "    \"batch_size\": 16,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"input_size\": 1 * 28 * 28,\n",
    "    \"hidden_size\": 512,\n",
    "    \"num_classes\": 10,\n",
    "    \"num_workers\": 16,    # used by the dataloader, more workers means faster data preparation, but for us this is not a bottleneck here\n",
    "}\n",
    "\n",
    "\n",
    "model = TwoLayerNet(hparams)\n",
    "data=FashionMNISTDataModule(hparams)\n",
    "data.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " PyTorch Lightning provides ample flexibility for training using [`Trainer`](https://pytorch-lightning.readthedocs.io/en/latest/trainer.html) class.\n",
    "Have a look at the documentation to know more about them!\n",
    "\n",
    "Let's initialize it now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=2,\n",
    "    accelerator=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument `max_epochs` sets the maximum number of epochs for training. \n",
    "The argument `weights_summary` prints a summary of the number of weights per layer at the beginning of the training. Set it to None if the summary is not required.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the actual training cell. The [`fit`](https://pytorch-lightning.readthedocs.io/en/latest/_modules/pytorch_lightning/trainer/trainer.html#Trainer.fit) function takes in the model and data to train the model with a lot more optional arguments for customization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 407 K \n",
      "-------------------------------------\n",
      "407 K     Trainable params\n",
      "0         Non-trainable params\n",
      "407 K     Total params\n",
      "1.628     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  83%|████████████████████▊    | 3125/3750 [00:19<00:03, 163.11it/s, loss=0.645, v_num=1, acc=0.750]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                      | 0/625 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  83%|████████████████████▊    | 3126/3750 [00:20<00:03, 156.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  83%|████████████████████▊    | 3127/3750 [00:20<00:03, 156.23it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  83%|████████████████████▊    | 3128/3750 [00:20<00:03, 156.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  83%|████████████████████▊    | 3129/3750 [00:20<00:03, 156.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  83%|████████████████████▊    | 3130/3750 [00:20<00:03, 156.26it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  83%|████████████████████▊    | 3131/3750 [00:20<00:03, 156.28it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|████████████████████▉    | 3132/3750 [00:20<00:03, 156.31it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|████████████████████▉    | 3133/3750 [00:20<00:03, 156.23it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|████████████████████▉    | 3134/3750 [00:20<00:03, 156.25it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|████████████████████▉    | 3135/3750 [00:20<00:03, 156.28it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|████████████████████▉    | 3136/3750 [00:20<00:03, 156.30it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|████████████████████▉    | 3137/3750 [00:20<00:03, 156.32it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|████████████████████▉    | 3138/3750 [00:20<00:03, 156.35it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|████████████████████▉    | 3139/3750 [00:20<00:03, 156.35it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|████████████████████▉    | 3140/3750 [00:20<00:03, 156.37it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|████████████████████▉    | 3141/3750 [00:20<00:03, 156.39it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|████████████████████▉    | 3142/3750 [00:20<00:03, 156.40it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|████████████████████▉    | 3143/3750 [00:20<00:03, 156.43it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|████████████████████▉    | 3144/3750 [00:20<00:03, 156.45it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|████████████████████▉    | 3145/3750 [00:20<00:03, 156.48it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|████████████████████▉    | 3146/3750 [00:20<00:03, 156.50it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|████████████████████▉    | 3147/3750 [00:20<00:03, 156.52it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|████████████████████▉    | 3148/3750 [00:20<00:03, 156.55it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|████████████████████▉    | 3149/3750 [00:20<00:03, 156.56it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████    | 3150/3750 [00:20<00:03, 156.58it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████    | 3151/3750 [00:20<00:03, 156.61it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████    | 3152/3750 [00:20<00:03, 156.63it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████    | 3153/3750 [00:20<00:03, 156.65it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████    | 3154/3750 [00:20<00:03, 156.68it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████    | 3155/3750 [00:20<00:03, 156.69it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████    | 3156/3750 [00:20<00:03, 156.71it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████    | 3157/3750 [00:20<00:03, 156.72it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████    | 3158/3750 [00:20<00:03, 156.73it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████    | 3159/3750 [00:20<00:03, 156.75it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████    | 3160/3750 [00:20<00:03, 156.77it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████    | 3161/3750 [00:20<00:03, 156.78it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████    | 3162/3750 [00:20<00:03, 156.80it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████    | 3163/3750 [00:20<00:03, 156.81it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████    | 3164/3750 [00:20<00:03, 156.83it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████    | 3165/3750 [00:20<00:03, 156.84it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████    | 3166/3750 [00:20<00:03, 156.85it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████    | 3167/3750 [00:20<00:03, 156.86it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████    | 3168/3750 [00:20<00:03, 156.88it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▏   | 3169/3750 [00:20<00:03, 156.90it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▏   | 3170/3750 [00:20<00:03, 156.91it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▏   | 3171/3750 [00:20<00:03, 156.92it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▏   | 3172/3750 [00:20<00:03, 156.93it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▏   | 3173/3750 [00:20<00:03, 156.94it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▏   | 3174/3750 [00:20<00:03, 156.95it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▏   | 3175/3750 [00:20<00:03, 156.95it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▏   | 3176/3750 [00:20<00:03, 156.97it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▏   | 3177/3750 [00:20<00:03, 156.99it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▏   | 3178/3750 [00:20<00:03, 157.00it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▏   | 3179/3750 [00:20<00:03, 157.02it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▏   | 3180/3750 [00:20<00:03, 157.04it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▏   | 3181/3750 [00:20<00:03, 157.06it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▏   | 3182/3750 [00:20<00:03, 157.07it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▏   | 3183/3750 [00:20<00:03, 157.09it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▏   | 3184/3750 [00:20<00:03, 157.11it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▏   | 3185/3750 [00:20<00:03, 157.12it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▏   | 3186/3750 [00:20<00:03, 157.14it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▏   | 3187/3750 [00:20<00:03, 157.15it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▎   | 3188/3750 [00:20<00:03, 157.17it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▎   | 3189/3750 [00:20<00:03, 157.19it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▎   | 3190/3750 [00:20<00:03, 157.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▎   | 3191/3750 [00:20<00:03, 157.23it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▎   | 3192/3750 [00:20<00:03, 157.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▎   | 3193/3750 [00:20<00:03, 157.26it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▎   | 3194/3750 [00:20<00:03, 157.28it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▎   | 3195/3750 [00:20<00:03, 157.29it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  85%|█████████████████████▎   | 3196/3750 [00:20<00:03, 157.31it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▎   | 3197/3750 [00:20<00:03, 157.33it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▎   | 3198/3750 [00:20<00:03, 157.34it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▎   | 3199/3750 [00:20<00:03, 157.34it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▎   | 3200/3750 [00:20<00:03, 157.35it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▎   | 3201/3750 [00:20<00:03, 157.36it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▎   | 3202/3750 [00:20<00:03, 157.38it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▎   | 3203/3750 [00:20<00:03, 157.39it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▎   | 3204/3750 [00:20<00:03, 157.40it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▎   | 3205/3750 [00:20<00:03, 157.41it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  85%|█████████████████████▎   | 3206/3750 [00:20<00:03, 157.43it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▍   | 3207/3750 [00:20<00:03, 157.45it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▍   | 3208/3750 [00:20<00:03, 157.46it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▍   | 3209/3750 [00:20<00:03, 157.48it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▍   | 3210/3750 [00:20<00:03, 157.49it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▍   | 3211/3750 [00:20<00:03, 157.50it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▍   | 3212/3750 [00:20<00:03, 157.52it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▍   | 3213/3750 [00:20<00:03, 157.53it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▍   | 3214/3750 [00:20<00:03, 157.55it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▍   | 3215/3750 [00:20<00:03, 157.57it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▍   | 3216/3750 [00:20<00:03, 157.59it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▍   | 3217/3750 [00:20<00:03, 157.61it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▍   | 3218/3750 [00:20<00:03, 157.63it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▍   | 3219/3750 [00:20<00:03, 157.64it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▍   | 3220/3750 [00:20<00:03, 157.66it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▍   | 3221/3750 [00:20<00:03, 157.68it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▍   | 3222/3750 [00:20<00:03, 157.70it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▍   | 3223/3750 [00:20<00:03, 157.72it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▍   | 3224/3750 [00:20<00:03, 157.74it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▌   | 3225/3750 [00:20<00:03, 157.75it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▌   | 3226/3750 [00:20<00:03, 157.78it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▌   | 3227/3750 [00:20<00:03, 157.79it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▌   | 3228/3750 [00:20<00:03, 157.81it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▌   | 3229/3750 [00:20<00:03, 157.83it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▌   | 3230/3750 [00:20<00:03, 157.85it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▌   | 3231/3750 [00:20<00:03, 157.87it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▌   | 3232/3750 [00:20<00:03, 157.89it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▌   | 3233/3750 [00:20<00:03, 157.91it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▌   | 3234/3750 [00:20<00:03, 157.92it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▌   | 3235/3750 [00:20<00:03, 157.94it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▌   | 3236/3750 [00:20<00:03, 157.96it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▌   | 3237/3750 [00:20<00:03, 157.98it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▌   | 3238/3750 [00:20<00:03, 158.00it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▌   | 3239/3750 [00:20<00:03, 158.01it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▌   | 3240/3750 [00:20<00:03, 158.02it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▌   | 3241/3750 [00:20<00:03, 158.04it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▌   | 3242/3750 [00:20<00:03, 158.06it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  86%|█████████████████████▌   | 3243/3750 [00:20<00:03, 158.08it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▋   | 3244/3750 [00:20<00:03, 158.10it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▋   | 3245/3750 [00:20<00:03, 158.11it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▋   | 3246/3750 [00:20<00:03, 158.13it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▋   | 3247/3750 [00:20<00:03, 158.15it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▋   | 3248/3750 [00:20<00:03, 158.17it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▋   | 3249/3750 [00:20<00:03, 158.19it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▋   | 3250/3750 [00:20<00:03, 158.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▋   | 3251/3750 [00:20<00:03, 158.23it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▋   | 3252/3750 [00:20<00:03, 158.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▋   | 3253/3750 [00:20<00:03, 158.26it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▋   | 3254/3750 [00:20<00:03, 158.28it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▋   | 3255/3750 [00:20<00:03, 158.30it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▋   | 3256/3750 [00:20<00:03, 158.32it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▋   | 3257/3750 [00:20<00:03, 158.34it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▋   | 3258/3750 [00:20<00:03, 158.36it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▋   | 3259/3750 [00:20<00:03, 158.37it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▋   | 3260/3750 [00:20<00:03, 158.39it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▋   | 3261/3750 [00:20<00:03, 158.41it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▋   | 3262/3750 [00:20<00:03, 158.43it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▊   | 3263/3750 [00:20<00:03, 158.45it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▊   | 3264/3750 [00:20<00:03, 158.47it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▊   | 3265/3750 [00:20<00:03, 158.49it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▊   | 3266/3750 [00:20<00:03, 158.51it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▊   | 3267/3750 [00:20<00:03, 158.52it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▊   | 3268/3750 [00:20<00:03, 158.53it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  87%|█████████████████████▊   | 3269/3750 [00:20<00:03, 158.54it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▊   | 3270/3750 [00:20<00:03, 158.56it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▊   | 3271/3750 [00:20<00:03, 158.57it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▊   | 3272/3750 [00:20<00:03, 158.58it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▊   | 3273/3750 [00:20<00:03, 158.60it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▊   | 3274/3750 [00:20<00:03, 158.61it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▊   | 3275/3750 [00:20<00:02, 158.62it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▊   | 3276/3750 [00:20<00:02, 158.64it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▊   | 3277/3750 [00:20<00:02, 158.65it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▊   | 3278/3750 [00:20<00:02, 158.67it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▊   | 3279/3750 [00:20<00:02, 158.68it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▊   | 3280/3750 [00:20<00:02, 158.69it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  87%|█████████████████████▊   | 3281/3750 [00:20<00:02, 158.70it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|█████████████████████▉   | 3282/3750 [00:20<00:02, 158.71it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|█████████████████████▉   | 3283/3750 [00:20<00:02, 158.72it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|█████████████████████▉   | 3284/3750 [00:20<00:02, 158.73it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|█████████████████████▉   | 3285/3750 [00:20<00:02, 158.73it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|█████████████████████▉   | 3286/3750 [00:20<00:02, 158.73it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|█████████████████████▉   | 3287/3750 [00:20<00:02, 158.73it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|█████████████████████▉   | 3288/3750 [00:20<00:02, 158.73it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|█████████████████████▉   | 3289/3750 [00:20<00:02, 158.72it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|█████████████████████▉   | 3290/3750 [00:20<00:02, 158.71it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|█████████████████████▉   | 3291/3750 [00:20<00:02, 158.71it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|█████████████████████▉   | 3292/3750 [00:20<00:02, 158.71it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|█████████████████████▉   | 3293/3750 [00:20<00:02, 158.72it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|█████████████████████▉   | 3294/3750 [00:20<00:02, 158.73it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|█████████████████████▉   | 3295/3750 [00:20<00:02, 158.73it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|█████████████████████▉   | 3296/3750 [00:20<00:02, 158.74it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|█████████████████████▉   | 3297/3750 [00:20<00:02, 158.74it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|█████████████████████▉   | 3298/3750 [00:20<00:02, 158.74it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|█████████████████████▉   | 3299/3750 [00:20<00:02, 158.74it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|██████████████████████   | 3300/3750 [00:20<00:02, 158.75it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|██████████████████████   | 3301/3750 [00:20<00:02, 158.76it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|██████████████████████   | 3302/3750 [00:20<00:02, 158.76it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|██████████████████████   | 3303/3750 [00:20<00:02, 158.74it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|██████████████████████   | 3304/3750 [00:20<00:02, 158.74it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|██████████████████████   | 3305/3750 [00:20<00:02, 158.75it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|██████████████████████   | 3306/3750 [00:20<00:02, 158.76it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|██████████████████████   | 3307/3750 [00:20<00:02, 158.76it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|██████████████████████   | 3308/3750 [00:20<00:02, 158.76it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|██████████████████████   | 3309/3750 [00:20<00:02, 158.75it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|██████████████████████   | 3310/3750 [00:20<00:02, 158.76it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|██████████████████████   | 3311/3750 [00:20<00:02, 158.77it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|██████████████████████   | 3312/3750 [00:20<00:02, 158.78it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|██████████████████████   | 3313/3750 [00:20<00:02, 158.79it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|██████████████████████   | 3314/3750 [00:20<00:02, 158.80it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|██████████████████████   | 3315/3750 [00:20<00:02, 158.81it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|██████████████████████   | 3316/3750 [00:20<00:02, 158.81it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|██████████████████████   | 3317/3750 [00:20<00:02, 158.82it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  88%|██████████████████████   | 3318/3750 [00:20<00:02, 158.84it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▏  | 3319/3750 [00:20<00:02, 158.84it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▏  | 3320/3750 [00:20<00:02, 158.85it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▏  | 3321/3750 [00:20<00:02, 158.86it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▏  | 3322/3750 [00:20<00:02, 158.86it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▏  | 3323/3750 [00:20<00:02, 158.87it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▏  | 3324/3750 [00:20<00:02, 158.88it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▏  | 3325/3750 [00:20<00:02, 158.88it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▏  | 3326/3750 [00:20<00:02, 158.89it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▏  | 3327/3750 [00:20<00:02, 158.90it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▏  | 3328/3750 [00:20<00:02, 158.90it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▏  | 3329/3750 [00:20<00:02, 158.90it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▏  | 3330/3750 [00:20<00:02, 158.92it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▏  | 3331/3750 [00:20<00:02, 158.90it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▏  | 3332/3750 [00:20<00:02, 158.90it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▏  | 3333/3750 [00:20<00:02, 158.89it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▏  | 3334/3750 [00:20<00:02, 158.90it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▏  | 3335/3750 [00:20<00:02, 158.91it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▏  | 3336/3750 [00:20<00:02, 158.91it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▏  | 3337/3750 [00:20<00:02, 158.92it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▎  | 3338/3750 [00:21<00:02, 158.93it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▎  | 3339/3750 [00:21<00:02, 158.93it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▎  | 3340/3750 [00:21<00:02, 158.94it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▎  | 3341/3750 [00:21<00:02, 158.95it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  89%|██████████████████████▎  | 3342/3750 [00:21<00:02, 158.96it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▎  | 3343/3750 [00:21<00:02, 158.96it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▎  | 3344/3750 [00:21<00:02, 158.97it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▎  | 3345/3750 [00:21<00:02, 158.98it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▎  | 3346/3750 [00:21<00:02, 158.99it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▎  | 3347/3750 [00:21<00:02, 159.00it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▎  | 3348/3750 [00:21<00:02, 159.00it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▎  | 3349/3750 [00:21<00:02, 159.01it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▎  | 3350/3750 [00:21<00:02, 159.02it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▎  | 3351/3750 [00:21<00:02, 159.03it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▎  | 3352/3750 [00:21<00:02, 159.04it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▎  | 3353/3750 [00:21<00:02, 159.04it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▎  | 3354/3750 [00:21<00:02, 159.06it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▎  | 3355/3750 [00:21<00:02, 159.06it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████▎  | 3356/3750 [00:21<00:02, 159.07it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▍  | 3357/3750 [00:21<00:02, 159.09it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▍  | 3358/3750 [00:21<00:02, 159.10it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▍  | 3359/3750 [00:21<00:02, 159.10it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▍  | 3360/3750 [00:21<00:02, 159.11it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▍  | 3361/3750 [00:21<00:02, 159.12it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▍  | 3362/3750 [00:21<00:02, 159.13it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▍  | 3363/3750 [00:21<00:02, 159.14it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▍  | 3364/3750 [00:21<00:02, 159.15it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▍  | 3365/3750 [00:21<00:02, 159.16it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▍  | 3366/3750 [00:21<00:02, 159.17it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▍  | 3367/3750 [00:21<00:02, 159.17it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▍  | 3368/3750 [00:21<00:02, 159.18it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▍  | 3369/3750 [00:21<00:02, 159.18it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▍  | 3370/3750 [00:21<00:02, 159.19it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▍  | 3371/3750 [00:21<00:02, 159.20it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▍  | 3372/3750 [00:21<00:02, 159.20it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▍  | 3373/3750 [00:21<00:02, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▍  | 3374/3750 [00:21<00:02, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▌  | 3375/3750 [00:21<00:02, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▌  | 3376/3750 [00:21<00:02, 159.23it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▌  | 3377/3750 [00:21<00:02, 159.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▌  | 3378/3750 [00:21<00:02, 159.25it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▌  | 3379/3750 [00:21<00:02, 159.26it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▌  | 3380/3750 [00:21<00:02, 159.27it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▌  | 3381/3750 [00:21<00:02, 159.27it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▌  | 3382/3750 [00:21<00:02, 159.28it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▌  | 3383/3750 [00:21<00:02, 159.29it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▌  | 3384/3750 [00:21<00:02, 159.29it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▌  | 3385/3750 [00:21<00:02, 159.30it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▌  | 3386/3750 [00:21<00:02, 159.30it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▌  | 3387/3750 [00:21<00:02, 159.30it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▌  | 3388/3750 [00:21<00:02, 159.29it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▌  | 3389/3750 [00:21<00:02, 159.27it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▌  | 3390/3750 [00:21<00:02, 159.28it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▌  | 3391/3750 [00:21<00:02, 159.28it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▌  | 3392/3750 [00:21<00:02, 159.28it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  90%|██████████████████████▌  | 3393/3750 [00:21<00:02, 159.28it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▋  | 3394/3750 [00:21<00:02, 159.28it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▋  | 3395/3750 [00:21<00:02, 159.28it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▋  | 3396/3750 [00:21<00:02, 159.28it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▋  | 3397/3750 [00:21<00:02, 159.28it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▋  | 3398/3750 [00:21<00:02, 159.28it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▋  | 3399/3750 [00:21<00:02, 159.29it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▋  | 3400/3750 [00:21<00:02, 159.28it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▋  | 3401/3750 [00:21<00:02, 159.27it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▋  | 3402/3750 [00:21<00:02, 159.27it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▋  | 3403/3750 [00:21<00:02, 159.26it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▋  | 3404/3750 [00:21<00:02, 159.26it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▋  | 3405/3750 [00:21<00:02, 159.25it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▋  | 3406/3750 [00:21<00:02, 159.25it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▋  | 3407/3750 [00:21<00:02, 159.25it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▋  | 3408/3750 [00:21<00:02, 159.25it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▋  | 3409/3750 [00:21<00:02, 159.25it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▋  | 3410/3750 [00:21<00:02, 159.25it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▋  | 3411/3750 [00:21<00:02, 159.25it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▋  | 3412/3750 [00:21<00:02, 159.25it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▊  | 3413/3750 [00:21<00:02, 159.25it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▊  | 3414/3750 [00:21<00:02, 159.25it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  91%|██████████████████████▊  | 3415/3750 [00:21<00:02, 159.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▊  | 3416/3750 [00:21<00:02, 159.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▊  | 3417/3750 [00:21<00:02, 159.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▊  | 3418/3750 [00:21<00:02, 159.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▊  | 3419/3750 [00:21<00:02, 159.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▊  | 3420/3750 [00:21<00:02, 159.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▊  | 3421/3750 [00:21<00:02, 159.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▊  | 3422/3750 [00:21<00:02, 159.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▊  | 3423/3750 [00:21<00:02, 159.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▊  | 3424/3750 [00:21<00:02, 159.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▊  | 3425/3750 [00:21<00:02, 159.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▊  | 3426/3750 [00:21<00:02, 159.23it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▊  | 3427/3750 [00:21<00:02, 159.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▊  | 3428/3750 [00:21<00:02, 159.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▊  | 3429/3750 [00:21<00:02, 159.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▊  | 3430/3750 [00:21<00:02, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████▊  | 3431/3750 [00:21<00:02, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████▉  | 3432/3750 [00:21<00:01, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████▉  | 3433/3750 [00:21<00:01, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████▉  | 3434/3750 [00:21<00:01, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████▉  | 3435/3750 [00:21<00:01, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████▉  | 3436/3750 [00:21<00:01, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████▉  | 3437/3750 [00:21<00:01, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████▉  | 3438/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████▉  | 3439/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████▉  | 3440/3750 [00:21<00:01, 159.23it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████▉  | 3441/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████▉  | 3442/3750 [00:21<00:01, 159.23it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████▉  | 3443/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████▉  | 3444/3750 [00:21<00:01, 159.23it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████▉  | 3445/3750 [00:21<00:01, 159.23it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████▉  | 3446/3750 [00:21<00:01, 159.23it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████▉  | 3447/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████▉  | 3448/3750 [00:21<00:01, 159.23it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|██████████████████████▉  | 3449/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████  | 3450/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████  | 3451/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████  | 3452/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████  | 3453/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████  | 3454/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████  | 3455/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████  | 3456/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████  | 3457/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████  | 3458/3750 [00:21<00:01, 159.23it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████  | 3459/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████  | 3460/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████  | 3461/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████  | 3462/3750 [00:21<00:01, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████  | 3463/3750 [00:21<00:01, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████  | 3464/3750 [00:21<00:01, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████  | 3465/3750 [00:21<00:01, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████  | 3466/3750 [00:21<00:01, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████  | 3467/3750 [00:21<00:01, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████  | 3468/3750 [00:21<00:01, 159.20it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▏ | 3469/3750 [00:21<00:01, 159.20it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▏ | 3470/3750 [00:21<00:01, 159.19it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▏ | 3471/3750 [00:21<00:01, 159.18it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▏ | 3472/3750 [00:21<00:01, 159.19it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▏ | 3473/3750 [00:21<00:01, 159.18it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▏ | 3474/3750 [00:21<00:01, 159.19it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▏ | 3475/3750 [00:21<00:01, 159.19it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▏ | 3476/3750 [00:21<00:01, 159.20it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▏ | 3477/3750 [00:21<00:01, 159.20it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▏ | 3478/3750 [00:21<00:01, 159.20it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▏ | 3479/3750 [00:21<00:01, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▏ | 3480/3750 [00:21<00:01, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▏ | 3481/3750 [00:21<00:01, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▏ | 3482/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▏ | 3483/3750 [00:21<00:01, 159.19it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▏ | 3484/3750 [00:21<00:01, 159.19it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▏ | 3485/3750 [00:21<00:01, 159.18it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▏ | 3486/3750 [00:21<00:01, 159.19it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▏ | 3487/3750 [00:21<00:01, 159.20it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  93%|███████████████████████▎ | 3488/3750 [00:21<00:01, 159.20it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▎ | 3489/3750 [00:21<00:01, 159.20it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▎ | 3490/3750 [00:21<00:01, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▎ | 3491/3750 [00:21<00:01, 159.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▎ | 3492/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▎ | 3493/3750 [00:21<00:01, 159.23it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▎ | 3494/3750 [00:21<00:01, 159.23it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▎ | 3495/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▎ | 3496/3750 [00:21<00:01, 159.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▎ | 3497/3750 [00:21<00:01, 159.23it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▎ | 3498/3750 [00:21<00:01, 159.23it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▎ | 3499/3750 [00:21<00:01, 159.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▎ | 3500/3750 [00:21<00:01, 159.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▎ | 3501/3750 [00:21<00:01, 159.25it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▎ | 3502/3750 [00:21<00:01, 159.25it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▎ | 3503/3750 [00:21<00:01, 159.25it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▎ | 3504/3750 [00:22<00:01, 159.25it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▎ | 3505/3750 [00:22<00:01, 159.26it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  93%|███████████████████████▎ | 3506/3750 [00:22<00:01, 159.26it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▍ | 3507/3750 [00:22<00:01, 159.26it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▍ | 3508/3750 [00:22<00:01, 159.27it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▍ | 3509/3750 [00:22<00:01, 159.27it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▍ | 3510/3750 [00:22<00:01, 159.27it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▍ | 3511/3750 [00:22<00:01, 159.28it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▍ | 3512/3750 [00:22<00:01, 159.29it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▍ | 3513/3750 [00:22<00:01, 159.30it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▍ | 3514/3750 [00:22<00:01, 159.29it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▍ | 3515/3750 [00:22<00:01, 159.29it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▍ | 3516/3750 [00:22<00:01, 159.29it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▍ | 3517/3750 [00:22<00:01, 159.29it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▍ | 3518/3750 [00:22<00:01, 159.30it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▍ | 3519/3750 [00:22<00:01, 159.30it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▍ | 3520/3750 [00:22<00:01, 159.30it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▍ | 3521/3750 [00:22<00:01, 159.30it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▍ | 3522/3750 [00:22<00:01, 159.31it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▍ | 3523/3750 [00:22<00:01, 159.31it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▍ | 3524/3750 [00:22<00:01, 159.31it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▌ | 3525/3750 [00:22<00:01, 159.32it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▌ | 3526/3750 [00:22<00:01, 159.31it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▌ | 3527/3750 [00:22<00:01, 159.32it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▌ | 3528/3750 [00:22<00:01, 159.33it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▌ | 3529/3750 [00:22<00:01, 159.34it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▌ | 3530/3750 [00:22<00:01, 159.33it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▌ | 3531/3750 [00:22<00:01, 159.32it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▌ | 3532/3750 [00:22<00:01, 159.33it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▌ | 3533/3750 [00:22<00:01, 159.34it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▌ | 3534/3750 [00:22<00:01, 159.34it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▌ | 3535/3750 [00:22<00:01, 159.33it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▌ | 3536/3750 [00:22<00:01, 159.33it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▌ | 3537/3750 [00:22<00:01, 159.34it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▌ | 3538/3750 [00:22<00:01, 159.34it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▌ | 3539/3750 [00:22<00:01, 159.34it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▌ | 3540/3750 [00:22<00:01, 159.34it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▌ | 3541/3750 [00:22<00:01, 159.35it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▌ | 3542/3750 [00:22<00:01, 159.34it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  94%|███████████████████████▌ | 3543/3750 [00:22<00:01, 159.34it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▋ | 3544/3750 [00:22<00:01, 159.35it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▋ | 3545/3750 [00:22<00:01, 159.34it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▋ | 3546/3750 [00:22<00:01, 159.35it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▋ | 3547/3750 [00:22<00:01, 159.35it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▋ | 3548/3750 [00:22<00:01, 159.36it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▋ | 3549/3750 [00:22<00:01, 159.37it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▋ | 3550/3750 [00:22<00:01, 159.38it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▋ | 3551/3750 [00:22<00:01, 159.38it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▋ | 3552/3750 [00:22<00:01, 159.40it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▋ | 3553/3750 [00:22<00:01, 159.42it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▋ | 3554/3750 [00:22<00:01, 159.43it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▋ | 3555/3750 [00:22<00:01, 159.45it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▋ | 3556/3750 [00:22<00:01, 159.47it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▋ | 3557/3750 [00:22<00:01, 159.48it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▋ | 3558/3750 [00:22<00:01, 159.49it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▋ | 3559/3750 [00:22<00:01, 159.50it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▋ | 3560/3750 [00:22<00:01, 159.52it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  95%|███████████████████████▋ | 3561/3750 [00:22<00:01, 159.53it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▋ | 3562/3750 [00:22<00:01, 159.54it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▊ | 3563/3750 [00:22<00:01, 159.55it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▊ | 3564/3750 [00:22<00:01, 159.56it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▊ | 3565/3750 [00:22<00:01, 159.57it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▊ | 3566/3750 [00:22<00:01, 159.57it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▊ | 3567/3750 [00:22<00:01, 159.59it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▊ | 3568/3750 [00:22<00:01, 159.60it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▊ | 3569/3750 [00:22<00:01, 159.60it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▊ | 3570/3750 [00:22<00:01, 159.61it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▊ | 3571/3750 [00:22<00:01, 159.62it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▊ | 3572/3750 [00:22<00:01, 159.63it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▊ | 3573/3750 [00:22<00:01, 159.63it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▊ | 3574/3750 [00:22<00:01, 159.64it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▊ | 3575/3750 [00:22<00:01, 159.66it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▊ | 3576/3750 [00:22<00:01, 159.67it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▊ | 3577/3750 [00:22<00:01, 159.68it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▊ | 3578/3750 [00:22<00:01, 159.69it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▊ | 3579/3750 [00:22<00:01, 159.70it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▊ | 3580/3750 [00:22<00:01, 159.71it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  95%|███████████████████████▊ | 3581/3750 [00:22<00:01, 159.72it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████▉ | 3582/3750 [00:22<00:01, 159.74it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████▉ | 3583/3750 [00:22<00:01, 159.75it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████▉ | 3584/3750 [00:22<00:01, 159.76it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████▉ | 3585/3750 [00:22<00:01, 159.77it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████▉ | 3586/3750 [00:22<00:01, 159.78it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████▉ | 3587/3750 [00:22<00:01, 159.79it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████▉ | 3588/3750 [00:22<00:01, 159.81it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████▉ | 3589/3750 [00:22<00:01, 159.81it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████▉ | 3590/3750 [00:22<00:01, 159.83it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████▉ | 3591/3750 [00:22<00:00, 159.84it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████▉ | 3592/3750 [00:22<00:00, 159.85it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████▉ | 3593/3750 [00:22<00:00, 159.87it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████▉ | 3594/3750 [00:22<00:00, 159.88it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████▉ | 3595/3750 [00:22<00:00, 159.89it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████▉ | 3596/3750 [00:22<00:00, 159.90it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████▉ | 3597/3750 [00:22<00:00, 159.91it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████▉ | 3598/3750 [00:22<00:00, 159.92it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████▉ | 3599/3750 [00:22<00:00, 159.94it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████ | 3600/3750 [00:22<00:00, 159.95it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████ | 3601/3750 [00:22<00:00, 159.96it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████ | 3602/3750 [00:22<00:00, 159.97it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████ | 3603/3750 [00:22<00:00, 159.98it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████ | 3604/3750 [00:22<00:00, 159.99it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████ | 3605/3750 [00:22<00:00, 160.01it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████ | 3606/3750 [00:22<00:00, 160.02it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████ | 3607/3750 [00:22<00:00, 160.03it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████ | 3608/3750 [00:22<00:00, 160.05it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████ | 3609/3750 [00:22<00:00, 160.07it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████ | 3610/3750 [00:22<00:00, 160.08it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████ | 3611/3750 [00:22<00:00, 160.10it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████ | 3612/3750 [00:22<00:00, 160.12it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████ | 3613/3750 [00:22<00:00, 160.14it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████ | 3614/3750 [00:22<00:00, 160.15it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████ | 3615/3750 [00:22<00:00, 160.17it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████ | 3616/3750 [00:22<00:00, 160.19it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████ | 3617/3750 [00:22<00:00, 160.21it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████ | 3618/3750 [00:22<00:00, 160.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▏| 3619/3750 [00:22<00:00, 160.24it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▏| 3620/3750 [00:22<00:00, 160.26it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▏| 3621/3750 [00:22<00:00, 160.28it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▏| 3622/3750 [00:22<00:00, 160.30it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▏| 3623/3750 [00:22<00:00, 160.31it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▏| 3624/3750 [00:22<00:00, 160.32it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▏| 3625/3750 [00:22<00:00, 160.34it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▏| 3626/3750 [00:22<00:00, 160.35it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▏| 3627/3750 [00:22<00:00, 160.37it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▏| 3628/3750 [00:22<00:00, 160.38it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▏| 3629/3750 [00:22<00:00, 160.40it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▏| 3630/3750 [00:22<00:00, 160.42it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▏| 3631/3750 [00:22<00:00, 160.44it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▏| 3632/3750 [00:22<00:00, 160.45it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▏| 3633/3750 [00:22<00:00, 160.47it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  97%|████████████████████████▏| 3634/3750 [00:22<00:00, 160.48it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▏| 3635/3750 [00:22<00:00, 160.50it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▏| 3636/3750 [00:22<00:00, 160.52it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▏| 3637/3750 [00:22<00:00, 160.53it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▎| 3638/3750 [00:22<00:00, 160.55it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▎| 3639/3750 [00:22<00:00, 160.57it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▎| 3640/3750 [00:22<00:00, 160.59it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▎| 3641/3750 [00:22<00:00, 160.60it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▎| 3642/3750 [00:22<00:00, 160.62it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▎| 3643/3750 [00:22<00:00, 160.64it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▎| 3644/3750 [00:22<00:00, 160.65it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▎| 3645/3750 [00:22<00:00, 160.67it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▎| 3646/3750 [00:22<00:00, 160.69it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▎| 3647/3750 [00:22<00:00, 160.71it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▎| 3648/3750 [00:22<00:00, 160.73it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▎| 3649/3750 [00:22<00:00, 160.74it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▎| 3650/3750 [00:22<00:00, 160.76it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▎| 3651/3750 [00:22<00:00, 160.78it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▎| 3652/3750 [00:22<00:00, 160.80it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▎| 3653/3750 [00:22<00:00, 160.81it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▎| 3654/3750 [00:22<00:00, 160.83it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▎| 3655/3750 [00:22<00:00, 160.85it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  97%|████████████████████████▎| 3656/3750 [00:22<00:00, 160.86it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▍| 3657/3750 [00:22<00:00, 160.88it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▍| 3658/3750 [00:22<00:00, 160.90it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▍| 3659/3750 [00:22<00:00, 160.91it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▍| 3660/3750 [00:22<00:00, 160.93it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▍| 3661/3750 [00:22<00:00, 160.95it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▍| 3662/3750 [00:22<00:00, 160.97it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▍| 3663/3750 [00:22<00:00, 160.98it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▍| 3664/3750 [00:22<00:00, 161.00it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▍| 3665/3750 [00:22<00:00, 161.02it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▍| 3666/3750 [00:22<00:00, 161.03it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▍| 3667/3750 [00:22<00:00, 161.05it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▍| 3668/3750 [00:22<00:00, 161.07it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▍| 3669/3750 [00:22<00:00, 161.08it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▍| 3670/3750 [00:22<00:00, 161.10it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▍| 3671/3750 [00:22<00:00, 161.12it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▍| 3672/3750 [00:22<00:00, 161.13it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▍| 3673/3750 [00:22<00:00, 161.15it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▍| 3674/3750 [00:22<00:00, 161.17it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▌| 3675/3750 [00:22<00:00, 161.19it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▌| 3676/3750 [00:22<00:00, 161.20it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▌| 3677/3750 [00:22<00:00, 161.22it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▌| 3678/3750 [00:22<00:00, 161.23it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▌| 3679/3750 [00:22<00:00, 161.25it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▌| 3680/3750 [00:22<00:00, 161.26it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▌| 3681/3750 [00:22<00:00, 161.28it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▌| 3682/3750 [00:22<00:00, 161.29it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▌| 3683/3750 [00:22<00:00, 161.31it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▌| 3684/3750 [00:22<00:00, 161.33it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▌| 3685/3750 [00:22<00:00, 161.34it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▌| 3686/3750 [00:22<00:00, 161.36it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▌| 3687/3750 [00:22<00:00, 161.36it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▌| 3688/3750 [00:22<00:00, 161.38it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▌| 3689/3750 [00:22<00:00, 161.39it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▌| 3690/3750 [00:22<00:00, 161.41it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▌| 3691/3750 [00:22<00:00, 161.42it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▌| 3692/3750 [00:22<00:00, 161.43it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████▌| 3693/3750 [00:22<00:00, 161.45it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▋| 3694/3750 [00:22<00:00, 161.46it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▋| 3695/3750 [00:22<00:00, 161.48it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▋| 3696/3750 [00:22<00:00, 161.49it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▋| 3697/3750 [00:22<00:00, 161.51it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▋| 3698/3750 [00:22<00:00, 161.52it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▋| 3699/3750 [00:22<00:00, 161.54it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▋| 3700/3750 [00:22<00:00, 161.55it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▋| 3701/3750 [00:22<00:00, 161.56it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▋| 3702/3750 [00:22<00:00, 161.57it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▋| 3703/3750 [00:22<00:00, 161.59it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▋| 3704/3750 [00:22<00:00, 161.60it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▋| 3705/3750 [00:22<00:00, 161.61it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▋| 3706/3750 [00:22<00:00, 161.62it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  99%|████████████████████████▋| 3707/3750 [00:22<00:00, 161.63it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▋| 3708/3750 [00:22<00:00, 161.63it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▋| 3709/3750 [00:22<00:00, 161.64it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▋| 3710/3750 [00:22<00:00, 161.65it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▋| 3711/3750 [00:22<00:00, 161.67it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▋| 3712/3750 [00:22<00:00, 161.67it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▊| 3713/3750 [00:22<00:00, 161.68it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▊| 3714/3750 [00:22<00:00, 161.69it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▊| 3715/3750 [00:22<00:00, 161.70it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▊| 3716/3750 [00:22<00:00, 161.71it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▊| 3717/3750 [00:22<00:00, 161.72it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▊| 3718/3750 [00:22<00:00, 161.73it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▊| 3719/3750 [00:22<00:00, 161.75it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▊| 3720/3750 [00:22<00:00, 161.76it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▊| 3721/3750 [00:23<00:00, 161.77it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▊| 3722/3750 [00:23<00:00, 161.78it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▊| 3723/3750 [00:23<00:00, 161.79it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▊| 3724/3750 [00:23<00:00, 161.80it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▊| 3725/3750 [00:23<00:00, 161.81it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▊| 3726/3750 [00:23<00:00, 161.83it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▊| 3727/3750 [00:23<00:00, 161.84it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▊| 3728/3750 [00:23<00:00, 161.85it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▊| 3729/3750 [00:23<00:00, 161.87it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▊| 3730/3750 [00:23<00:00, 161.88it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0:  99%|████████████████████████▊| 3731/3750 [00:23<00:00, 161.88it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████▉| 3732/3750 [00:23<00:00, 161.90it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████▉| 3733/3750 [00:23<00:00, 161.91it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████▉| 3734/3750 [00:23<00:00, 161.92it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████▉| 3735/3750 [00:23<00:00, 161.93it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████▉| 3736/3750 [00:23<00:00, 161.95it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████▉| 3737/3750 [00:23<00:00, 161.96it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████▉| 3738/3750 [00:23<00:00, 161.97it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████▉| 3739/3750 [00:23<00:00, 161.99it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████▉| 3740/3750 [00:23<00:00, 162.00it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████▉| 3741/3750 [00:23<00:00, 162.01it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████▉| 3742/3750 [00:23<00:00, 162.02it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████▉| 3743/3750 [00:23<00:00, 162.03it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████▉| 3744/3750 [00:23<00:00, 162.05it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████▉| 3745/3750 [00:23<00:00, 162.06it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████▉| 3746/3750 [00:23<00:00, 162.07it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████▉| 3747/3750 [00:23<00:00, 162.08it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████▉| 3748/3750 [00:23<00:00, 162.10it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████▉| 3749/3750 [00:23<00:00, 162.11it/s, loss=0.645, v_num=1, acc=0.750]\u001b[A\n",
      "Epoch 0: 100%|█████████| 3750/3750 [00:23<00:00, 161.99it/s, loss=0.645, v_num=1, acc=0.750, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 3125/3750 [00:40<00:08, 76.31it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                      | 0/625 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 3126/3750 [00:41<00:08, 74.64it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 3127/3750 [00:41<00:08, 74.65it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 3128/3750 [00:41<00:08, 74.66it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 3129/3750 [00:41<00:08, 74.68it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 3130/3750 [00:41<00:08, 74.69it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 3131/3750 [00:41<00:08, 74.71it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 3132/3750 [00:41<00:08, 74.72it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 3133/3750 [00:41<00:08, 74.72it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 3134/3750 [00:41<00:08, 74.74it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 3135/3750 [00:41<00:08, 74.75it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 3136/3750 [00:41<00:08, 74.76it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 3137/3750 [00:41<00:08, 74.78it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 3138/3750 [00:41<00:08, 74.78it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 3139/3750 [00:41<00:08, 74.79it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 3140/3750 [00:41<00:08, 74.81it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3141/3750 [00:41<00:08, 74.83it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3142/3750 [00:41<00:08, 74.84it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3143/3750 [00:41<00:08, 74.86it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3144/3750 [00:41<00:08, 74.87it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3145/3750 [00:41<00:08, 74.89it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3146/3750 [00:42<00:08, 74.90it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3147/3750 [00:42<00:08, 74.92it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3148/3750 [00:42<00:08, 74.94it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3149/3750 [00:42<00:08, 74.95it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3150/3750 [00:42<00:08, 74.97it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3151/3750 [00:42<00:07, 74.99it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  84%|████████▍ | 3152/3750 [00:42<00:07, 75.00it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3153/3750 [00:42<00:07, 75.01it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3154/3750 [00:42<00:07, 75.03it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3155/3750 [00:42<00:07, 75.04it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3156/3750 [00:42<00:07, 75.06it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3157/3750 [00:42<00:07, 75.07it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3158/3750 [00:42<00:07, 75.09it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3159/3750 [00:42<00:07, 75.10it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3160/3750 [00:42<00:07, 75.12it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3161/3750 [00:42<00:07, 75.13it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3162/3750 [00:42<00:07, 75.14it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3163/3750 [00:42<00:07, 75.16it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3164/3750 [00:42<00:07, 75.17it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3165/3750 [00:42<00:07, 75.19it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3166/3750 [00:42<00:07, 75.20it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3167/3750 [00:42<00:07, 75.22it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 3168/3750 [00:42<00:07, 75.23it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 3169/3750 [00:42<00:07, 75.24it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 3170/3750 [00:42<00:07, 75.26it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 3171/3750 [00:42<00:07, 75.27it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 3172/3750 [00:42<00:07, 75.29it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 3173/3750 [00:42<00:07, 75.30it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 3174/3750 [00:42<00:07, 75.32it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 3175/3750 [00:42<00:07, 75.33it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 3176/3750 [00:42<00:07, 75.34it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 3177/3750 [00:42<00:07, 75.36it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 3178/3750 [00:42<00:07, 75.37it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 3179/3750 [00:42<00:07, 75.38it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 3180/3750 [00:42<00:07, 75.40it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 3181/3750 [00:42<00:07, 75.41it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 3182/3750 [00:42<00:07, 75.42it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 3183/3750 [00:42<00:07, 75.44it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 3184/3750 [00:42<00:07, 75.45it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 3185/3750 [00:42<00:07, 75.47it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 3186/3750 [00:42<00:07, 75.48it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 3187/3750 [00:42<00:07, 75.49it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 3188/3750 [00:42<00:07, 75.51it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 3189/3750 [00:42<00:07, 75.52it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 3190/3750 [00:42<00:07, 75.53it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 3191/3750 [00:42<00:07, 75.55it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 3192/3750 [00:42<00:07, 75.56it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 3193/3750 [00:42<00:07, 75.57it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 3194/3750 [00:42<00:07, 75.59it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 3195/3750 [00:42<00:07, 75.60it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 3196/3750 [00:42<00:07, 75.62it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 3197/3750 [00:42<00:07, 75.63it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 3198/3750 [00:42<00:07, 75.64it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 3199/3750 [00:42<00:07, 75.65it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 3200/3750 [00:42<00:07, 75.67it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 3201/3750 [00:42<00:07, 75.68it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 3202/3750 [00:42<00:07, 75.70it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 3203/3750 [00:42<00:07, 75.71it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 3204/3750 [00:42<00:07, 75.73it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 3205/3750 [00:42<00:07, 75.74it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 3206/3750 [00:42<00:07, 75.75it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3207/3750 [00:42<00:07, 75.77it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3208/3750 [00:42<00:07, 75.78it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3209/3750 [00:42<00:07, 75.79it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3210/3750 [00:42<00:07, 75.81it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3211/3750 [00:42<00:07, 75.82it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3212/3750 [00:42<00:07, 75.84it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3213/3750 [00:42<00:07, 75.85it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3214/3750 [00:42<00:07, 75.86it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3215/3750 [00:42<00:07, 75.87it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3216/3750 [00:42<00:07, 75.89it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3217/3750 [00:42<00:07, 75.90it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3218/3750 [00:42<00:07, 75.92it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3219/3750 [00:42<00:06, 75.93it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3220/3750 [00:42<00:06, 75.94it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3221/3750 [00:42<00:06, 75.96it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3222/3750 [00:42<00:06, 75.97it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3223/3750 [00:42<00:06, 75.99it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3224/3750 [00:42<00:06, 76.00it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  86%|████████▌ | 3225/3750 [00:42<00:06, 76.01it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3226/3750 [00:42<00:06, 76.03it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3227/3750 [00:42<00:06, 76.04it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3228/3750 [00:42<00:06, 76.06it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3229/3750 [00:42<00:06, 76.07it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3230/3750 [00:42<00:06, 76.08it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3231/3750 [00:42<00:06, 76.10it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3232/3750 [00:42<00:06, 76.11it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3233/3750 [00:42<00:06, 76.13it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 3234/3750 [00:42<00:06, 76.14it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 3235/3750 [00:42<00:06, 76.15it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 3236/3750 [00:42<00:06, 76.17it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 3237/3750 [00:42<00:06, 76.18it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 3238/3750 [00:42<00:06, 76.20it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 3239/3750 [00:42<00:06, 76.21it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 3240/3750 [00:42<00:06, 76.22it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 3241/3750 [00:42<00:06, 76.24it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 3242/3750 [00:42<00:06, 76.25it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 3243/3750 [00:42<00:06, 76.27it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3244/3750 [00:42<00:06, 76.28it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3245/3750 [00:42<00:06, 76.30it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3246/3750 [00:42<00:06, 76.31it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3247/3750 [00:42<00:06, 76.32it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3248/3750 [00:42<00:06, 76.34it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3249/3750 [00:42<00:06, 76.35it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3250/3750 [00:42<00:06, 76.36it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3251/3750 [00:42<00:06, 76.37it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3252/3750 [00:42<00:06, 76.39it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3253/3750 [00:42<00:06, 76.40it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3254/3750 [00:42<00:06, 76.41it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3255/3750 [00:42<00:06, 76.42it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3256/3750 [00:42<00:06, 76.43it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3257/3750 [00:42<00:06, 76.45it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3258/3750 [00:42<00:06, 76.46it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3259/3750 [00:42<00:06, 76.47it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3260/3750 [00:42<00:06, 76.48it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3261/3750 [00:42<00:06, 76.49it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3262/3750 [00:42<00:06, 76.50it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3263/3750 [00:42<00:06, 76.51it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3264/3750 [00:42<00:06, 76.52it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3265/3750 [00:42<00:06, 76.53it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3266/3750 [00:42<00:06, 76.55it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3267/3750 [00:42<00:06, 76.55it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3268/3750 [00:42<00:06, 76.56it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3269/3750 [00:42<00:06, 76.57it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3270/3750 [00:42<00:06, 76.58it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3271/3750 [00:42<00:06, 76.60it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3272/3750 [00:42<00:06, 76.61it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3273/3750 [00:42<00:06, 76.62it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3274/3750 [00:42<00:06, 76.64it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3275/3750 [00:42<00:06, 76.65it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3276/3750 [00:42<00:06, 76.67it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3277/3750 [00:42<00:06, 76.68it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3278/3750 [00:42<00:06, 76.69it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3279/3750 [00:42<00:06, 76.71it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3280/3750 [00:42<00:06, 76.72it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 3281/3750 [00:42<00:06, 76.74it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3282/3750 [00:42<00:06, 76.75it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3283/3750 [00:42<00:06, 76.76it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3284/3750 [00:42<00:06, 76.78it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3285/3750 [00:42<00:06, 76.79it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3286/3750 [00:42<00:06, 76.81it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3287/3750 [00:42<00:06, 76.82it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3288/3750 [00:42<00:06, 76.83it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3289/3750 [00:42<00:05, 76.85it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3290/3750 [00:42<00:05, 76.86it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3291/3750 [00:42<00:05, 76.88it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3292/3750 [00:42<00:05, 76.89it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3293/3750 [00:42<00:05, 76.90it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3294/3750 [00:42<00:05, 76.92it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3295/3750 [00:42<00:05, 76.93it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3296/3750 [00:42<00:05, 76.94it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3297/3750 [00:42<00:05, 76.95it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  88%|████████▊ | 3298/3750 [00:42<00:05, 76.97it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3299/3750 [00:42<00:05, 76.98it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3300/3750 [00:42<00:05, 76.99it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3301/3750 [00:42<00:05, 77.01it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3302/3750 [00:42<00:05, 77.02it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3303/3750 [00:42<00:05, 77.03it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3304/3750 [00:42<00:05, 77.04it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3305/3750 [00:42<00:05, 77.06it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3306/3750 [00:42<00:05, 77.07it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3307/3750 [00:42<00:05, 77.08it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3308/3750 [00:42<00:05, 77.09it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3309/3750 [00:42<00:05, 77.11it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3310/3750 [00:42<00:05, 77.12it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3311/3750 [00:42<00:05, 77.13it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3312/3750 [00:42<00:05, 77.14it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3313/3750 [00:42<00:05, 77.16it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3314/3750 [00:42<00:05, 77.17it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3315/3750 [00:42<00:05, 77.19it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3316/3750 [00:42<00:05, 77.20it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3317/3750 [00:42<00:05, 77.21it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 3318/3750 [00:42<00:05, 77.22it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 3319/3750 [00:42<00:05, 77.24it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 3320/3750 [00:42<00:05, 77.25it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 3321/3750 [00:42<00:05, 77.26it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 3322/3750 [00:42<00:05, 77.28it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 3323/3750 [00:42<00:05, 77.29it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 3324/3750 [00:42<00:05, 77.30it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 3325/3750 [00:43<00:05, 77.31it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 3326/3750 [00:43<00:05, 77.33it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 3327/3750 [00:43<00:05, 77.34it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 3328/3750 [00:43<00:05, 77.35it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3329/3750 [00:43<00:05, 77.37it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3330/3750 [00:43<00:05, 77.38it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3331/3750 [00:43<00:05, 77.39it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3332/3750 [00:43<00:05, 77.40it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3333/3750 [00:43<00:05, 77.42it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3334/3750 [00:43<00:05, 77.43it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3335/3750 [00:43<00:05, 77.44it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3336/3750 [00:43<00:05, 77.46it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3337/3750 [00:43<00:05, 77.47it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3338/3750 [00:43<00:05, 77.48it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3339/3750 [00:43<00:05, 77.50it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3340/3750 [00:43<00:05, 77.51it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3341/3750 [00:43<00:05, 77.52it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3342/3750 [00:43<00:05, 77.54it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3343/3750 [00:43<00:05, 77.55it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3344/3750 [00:43<00:05, 77.57it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3345/3750 [00:43<00:05, 77.58it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3346/3750 [00:43<00:05, 77.59it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3347/3750 [00:43<00:05, 77.61it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3348/3750 [00:43<00:05, 77.62it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3349/3750 [00:43<00:05, 77.63it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3350/3750 [00:43<00:05, 77.65it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3351/3750 [00:43<00:05, 77.66it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3352/3750 [00:43<00:05, 77.67it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3353/3750 [00:43<00:05, 77.68it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3354/3750 [00:43<00:05, 77.69it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3355/3750 [00:43<00:05, 77.71it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 3356/3750 [00:43<00:05, 77.72it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 3357/3750 [00:43<00:05, 77.73it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 3358/3750 [00:43<00:05, 77.74it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 3359/3750 [00:43<00:05, 77.75it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 3360/3750 [00:43<00:05, 77.77it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 3361/3750 [00:43<00:05, 77.78it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 3362/3750 [00:43<00:04, 77.79it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 3363/3750 [00:43<00:04, 77.81it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 3364/3750 [00:43<00:04, 77.82it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 3365/3750 [00:43<00:04, 77.83it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 3366/3750 [00:43<00:04, 77.85it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 3367/3750 [00:43<00:04, 77.86it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 3368/3750 [00:43<00:04, 77.87it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 3369/3750 [00:43<00:04, 77.88it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 3370/3750 [00:43<00:04, 77.90it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  90%|████████▉ | 3371/3750 [00:43<00:04, 77.91it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 3372/3750 [00:43<00:04, 77.92it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 3373/3750 [00:43<00:04, 77.94it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 3374/3750 [00:43<00:04, 77.95it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3375/3750 [00:43<00:04, 77.96it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3376/3750 [00:43<00:04, 77.98it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3377/3750 [00:43<00:04, 77.99it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3378/3750 [00:43<00:04, 78.00it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3379/3750 [00:43<00:04, 78.02it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3380/3750 [00:43<00:04, 78.03it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3381/3750 [00:43<00:04, 78.05it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3382/3750 [00:43<00:04, 78.06it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3383/3750 [00:43<00:04, 78.07it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3384/3750 [00:43<00:04, 78.08it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3385/3750 [00:43<00:04, 78.10it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3386/3750 [00:43<00:04, 78.11it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3387/3750 [00:43<00:04, 78.12it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3388/3750 [00:43<00:04, 78.14it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3389/3750 [00:43<00:04, 78.15it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3390/3750 [00:43<00:04, 78.16it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3391/3750 [00:43<00:04, 78.18it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3392/3750 [00:43<00:04, 78.19it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 3393/3750 [00:43<00:04, 78.20it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3394/3750 [00:43<00:04, 78.22it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3395/3750 [00:43<00:04, 78.23it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3396/3750 [00:43<00:04, 78.24it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3397/3750 [00:43<00:04, 78.25it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3398/3750 [00:43<00:04, 78.27it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3399/3750 [00:43<00:04, 78.28it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3400/3750 [00:43<00:04, 78.29it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3401/3750 [00:43<00:04, 78.31it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3402/3750 [00:43<00:04, 78.32it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3403/3750 [00:43<00:04, 78.33it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3404/3750 [00:43<00:04, 78.35it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3405/3750 [00:43<00:04, 78.36it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3406/3750 [00:43<00:04, 78.37it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3407/3750 [00:43<00:04, 78.39it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3408/3750 [00:43<00:04, 78.40it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3409/3750 [00:43<00:04, 78.42it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3410/3750 [00:43<00:04, 78.43it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3411/3750 [00:43<00:04, 78.44it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3412/3750 [00:43<00:04, 78.46it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3413/3750 [00:43<00:04, 78.47it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3414/3750 [00:43<00:04, 78.48it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3415/3750 [00:43<00:04, 78.49it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3416/3750 [00:43<00:04, 78.51it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3417/3750 [00:43<00:04, 78.52it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3418/3750 [00:43<00:04, 78.54it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3419/3750 [00:43<00:04, 78.55it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3420/3750 [00:43<00:04, 78.56it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 3421/3750 [00:43<00:04, 78.58it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 3422/3750 [00:43<00:04, 78.59it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 3423/3750 [00:43<00:04, 78.60it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 3424/3750 [00:43<00:04, 78.62it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 3425/3750 [00:43<00:04, 78.63it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 3426/3750 [00:43<00:04, 78.64it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 3427/3750 [00:43<00:04, 78.66it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 3428/3750 [00:43<00:04, 78.67it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 3429/3750 [00:43<00:04, 78.68it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 3430/3750 [00:43<00:04, 78.70it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 3431/3750 [00:43<00:04, 78.71it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3432/3750 [00:43<00:04, 78.72it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3433/3750 [00:43<00:04, 78.73it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3434/3750 [00:43<00:04, 78.75it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3435/3750 [00:43<00:03, 78.76it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3436/3750 [00:43<00:03, 78.77it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3437/3750 [00:43<00:03, 78.79it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3438/3750 [00:43<00:03, 78.80it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3439/3750 [00:43<00:03, 78.81it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3440/3750 [00:43<00:03, 78.83it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3441/3750 [00:43<00:03, 78.84it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3442/3750 [00:43<00:03, 78.85it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3443/3750 [00:43<00:03, 78.87it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  92%|█████████▏| 3444/3750 [00:43<00:03, 78.88it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3445/3750 [00:43<00:03, 78.89it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3446/3750 [00:43<00:03, 78.91it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3447/3750 [00:43<00:03, 78.92it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3448/3750 [00:43<00:03, 78.93it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3449/3750 [00:43<00:03, 78.95it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3450/3750 [00:43<00:03, 78.96it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3451/3750 [00:43<00:03, 78.97it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3452/3750 [00:43<00:03, 78.99it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3453/3750 [00:43<00:03, 79.00it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3454/3750 [00:43<00:03, 79.01it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3455/3750 [00:43<00:03, 79.02it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3456/3750 [00:43<00:03, 79.04it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3457/3750 [00:43<00:03, 79.05it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3458/3750 [00:43<00:03, 79.06it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3459/3750 [00:43<00:03, 79.08it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3460/3750 [00:43<00:03, 79.09it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3461/3750 [00:43<00:03, 79.10it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3462/3750 [00:43<00:03, 79.11it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3463/3750 [00:43<00:03, 79.13it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3464/3750 [00:43<00:03, 79.14it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3465/3750 [00:43<00:03, 79.15it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3466/3750 [00:43<00:03, 79.17it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3467/3750 [00:43<00:03, 79.18it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 3468/3750 [00:43<00:03, 79.19it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3469/3750 [00:43<00:03, 79.21it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3470/3750 [00:43<00:03, 79.22it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3471/3750 [00:43<00:03, 79.23it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3472/3750 [00:43<00:03, 79.25it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3473/3750 [00:43<00:03, 79.26it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3474/3750 [00:43<00:03, 79.27it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3475/3750 [00:43<00:03, 79.29it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3476/3750 [00:43<00:03, 79.30it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3477/3750 [00:43<00:03, 79.32it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3478/3750 [00:43<00:03, 79.33it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3479/3750 [00:43<00:03, 79.34it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3480/3750 [00:43<00:03, 79.36it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3481/3750 [00:43<00:03, 79.37it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3482/3750 [00:43<00:03, 79.38it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3483/3750 [00:43<00:03, 79.39it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3484/3750 [00:43<00:03, 79.41it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3485/3750 [00:43<00:03, 79.42it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3486/3750 [00:43<00:03, 79.44it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3487/3750 [00:43<00:03, 79.45it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3488/3750 [00:43<00:03, 79.46it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3489/3750 [00:43<00:03, 79.48it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3490/3750 [00:43<00:03, 79.49it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3491/3750 [00:43<00:03, 79.50it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3492/3750 [00:43<00:03, 79.52it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3493/3750 [00:43<00:03, 79.53it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3494/3750 [00:43<00:03, 79.55it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3495/3750 [00:43<00:03, 79.56it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3496/3750 [00:43<00:03, 79.57it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3497/3750 [00:43<00:03, 79.58it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3498/3750 [00:43<00:03, 79.60it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3499/3750 [00:43<00:03, 79.61it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3500/3750 [00:43<00:03, 79.62it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3501/3750 [00:43<00:03, 79.64it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3502/3750 [00:43<00:03, 79.65it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3503/3750 [00:43<00:03, 79.67it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3504/3750 [00:43<00:03, 79.68it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3505/3750 [00:43<00:03, 79.69it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 3506/3750 [00:43<00:03, 79.71it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 3507/3750 [00:43<00:03, 79.72it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 3508/3750 [00:43<00:03, 79.73it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 3509/3750 [00:44<00:03, 79.75it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 3510/3750 [00:44<00:03, 79.76it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 3511/3750 [00:44<00:02, 79.77it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 3512/3750 [00:44<00:02, 79.78it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 3513/3750 [00:44<00:02, 79.79it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 3514/3750 [00:44<00:02, 79.81it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 3515/3750 [00:44<00:02, 79.82it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3516/3750 [00:44<00:02, 79.83it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  94%|█████████▍| 3517/3750 [00:44<00:02, 79.84it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3518/3750 [00:44<00:02, 79.86it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3519/3750 [00:44<00:02, 79.87it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3520/3750 [00:44<00:02, 79.88it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3521/3750 [00:44<00:02, 79.90it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3522/3750 [00:44<00:02, 79.91it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3523/3750 [00:44<00:02, 79.92it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3524/3750 [00:44<00:02, 79.94it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3525/3750 [00:44<00:02, 79.95it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3526/3750 [00:44<00:02, 79.96it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3527/3750 [00:44<00:02, 79.98it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3528/3750 [00:44<00:02, 79.99it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3529/3750 [00:44<00:02, 80.00it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3530/3750 [00:44<00:02, 80.01it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3531/3750 [00:44<00:02, 80.03it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3532/3750 [00:44<00:02, 80.04it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3533/3750 [00:44<00:02, 80.05it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3534/3750 [00:44<00:02, 80.07it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3535/3750 [00:44<00:02, 80.08it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3536/3750 [00:44<00:02, 80.09it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3537/3750 [00:44<00:02, 80.11it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3538/3750 [00:44<00:02, 80.12it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3539/3750 [00:44<00:02, 80.13it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3540/3750 [00:44<00:02, 80.14it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3541/3750 [00:44<00:02, 80.16it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3542/3750 [00:44<00:02, 80.17it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 3543/3750 [00:44<00:02, 80.18it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 3544/3750 [00:44<00:02, 80.19it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 3545/3750 [00:44<00:02, 80.20it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 3546/3750 [00:44<00:02, 80.22it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 3547/3750 [00:44<00:02, 80.23it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 3548/3750 [00:44<00:02, 80.24it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 3549/3750 [00:44<00:02, 80.26it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 3550/3750 [00:44<00:02, 80.27it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 3551/3750 [00:44<00:02, 80.28it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 3552/3750 [00:44<00:02, 80.30it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 3553/3750 [00:44<00:02, 80.31it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 3554/3750 [00:44<00:02, 80.32it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 3555/3750 [00:44<00:02, 80.34it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 3556/3750 [00:44<00:02, 80.35it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 3557/3750 [00:44<00:02, 80.36it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 3558/3750 [00:44<00:02, 80.38it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 3559/3750 [00:44<00:02, 80.39it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 3560/3750 [00:44<00:02, 80.40it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 3561/3750 [00:44<00:02, 80.42it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 3562/3750 [00:44<00:02, 80.43it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 3563/3750 [00:44<00:02, 80.44it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 3564/3750 [00:44<00:02, 80.46it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 3565/3750 [00:44<00:02, 80.47it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 3566/3750 [00:44<00:02, 80.48it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 3567/3750 [00:44<00:02, 80.50it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 3568/3750 [00:44<00:02, 80.51it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 3569/3750 [00:44<00:02, 80.52it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 3570/3750 [00:44<00:02, 80.54it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 3571/3750 [00:44<00:02, 80.55it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 3572/3750 [00:44<00:02, 80.56it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 3573/3750 [00:44<00:02, 80.58it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 3574/3750 [00:44<00:02, 80.59it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 3575/3750 [00:44<00:02, 80.60it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 3576/3750 [00:44<00:02, 80.62it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 3577/3750 [00:44<00:02, 80.63it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 3578/3750 [00:44<00:02, 80.64it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 3579/3750 [00:44<00:02, 80.66it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 3580/3750 [00:44<00:02, 80.67it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 3581/3750 [00:44<00:02, 80.68it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3582/3750 [00:44<00:02, 80.69it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3583/3750 [00:44<00:02, 80.70it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3584/3750 [00:44<00:02, 80.72it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3585/3750 [00:44<00:02, 80.73it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3586/3750 [00:44<00:02, 80.74it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3587/3750 [00:44<00:02, 80.75it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3588/3750 [00:44<00:02, 80.77it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3589/3750 [00:44<00:01, 80.78it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  96%|█████████▌| 3590/3750 [00:44<00:01, 80.79it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3591/3750 [00:44<00:01, 80.80it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3592/3750 [00:44<00:01, 80.81it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3593/3750 [00:44<00:01, 80.83it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3594/3750 [00:44<00:01, 80.84it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3595/3750 [00:44<00:01, 80.85it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3596/3750 [00:44<00:01, 80.86it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3597/3750 [00:44<00:01, 80.88it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3598/3750 [00:44<00:01, 80.89it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3599/3750 [00:44<00:01, 80.90it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3600/3750 [00:44<00:01, 80.92it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3601/3750 [00:44<00:01, 80.93it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3602/3750 [00:44<00:01, 80.94it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3603/3750 [00:44<00:01, 80.95it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3604/3750 [00:44<00:01, 80.97it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3605/3750 [00:44<00:01, 80.98it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3606/3750 [00:44<00:01, 80.99it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3607/3750 [00:44<00:01, 81.01it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3608/3750 [00:44<00:01, 81.02it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 3609/3750 [00:44<00:01, 81.03it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 3610/3750 [00:44<00:01, 81.04it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 3611/3750 [00:44<00:01, 81.06it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 3612/3750 [00:44<00:01, 81.07it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 3613/3750 [00:44<00:01, 81.08it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 3614/3750 [00:44<00:01, 81.09it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 3615/3750 [00:44<00:01, 81.11it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 3616/3750 [00:44<00:01, 81.12it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 3617/3750 [00:44<00:01, 81.13it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 3618/3750 [00:44<00:01, 81.14it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3619/3750 [00:44<00:01, 81.16it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3620/3750 [00:44<00:01, 81.17it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3621/3750 [00:44<00:01, 81.18it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3622/3750 [00:44<00:01, 81.19it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3623/3750 [00:44<00:01, 81.20it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3624/3750 [00:44<00:01, 81.22it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3625/3750 [00:44<00:01, 81.23it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3626/3750 [00:44<00:01, 81.24it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3627/3750 [00:44<00:01, 81.26it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3628/3750 [00:44<00:01, 81.27it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3629/3750 [00:44<00:01, 81.28it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3630/3750 [00:44<00:01, 81.29it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3631/3750 [00:44<00:01, 81.31it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3632/3750 [00:44<00:01, 81.32it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3633/3750 [00:44<00:01, 81.33it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3634/3750 [00:44<00:01, 81.33it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3635/3750 [00:44<00:01, 81.35it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3636/3750 [00:44<00:01, 81.36it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3637/3750 [00:44<00:01, 81.37it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3638/3750 [00:44<00:01, 81.38it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3639/3750 [00:44<00:01, 81.39it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3640/3750 [00:44<00:01, 81.40it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3641/3750 [00:44<00:01, 81.41it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3642/3750 [00:44<00:01, 81.43it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3643/3750 [00:44<00:01, 81.44it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3644/3750 [00:44<00:01, 81.45it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3645/3750 [00:44<00:01, 81.46it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3646/3750 [00:44<00:01, 81.47it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3647/3750 [00:44<00:01, 81.49it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3648/3750 [00:44<00:01, 81.50it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3649/3750 [00:44<00:01, 81.51it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3650/3750 [00:44<00:01, 81.52it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3651/3750 [00:44<00:01, 81.54it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3652/3750 [00:44<00:01, 81.55it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3653/3750 [00:44<00:01, 81.56it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3654/3750 [00:44<00:01, 81.57it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3655/3750 [00:44<00:01, 81.59it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3656/3750 [00:44<00:01, 81.60it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3657/3750 [00:44<00:01, 81.61it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3658/3750 [00:44<00:01, 81.62it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3659/3750 [00:44<00:01, 81.64it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3660/3750 [00:44<00:01, 81.65it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3661/3750 [00:44<00:01, 81.66it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3662/3750 [00:44<00:01, 81.67it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  98%|█████████▊| 3663/3750 [00:44<00:01, 81.69it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3664/3750 [00:44<00:01, 81.70it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3665/3750 [00:44<00:01, 81.71it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3666/3750 [00:44<00:01, 81.72it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3667/3750 [00:44<00:01, 81.74it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3668/3750 [00:44<00:01, 81.75it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3669/3750 [00:44<00:00, 81.76it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3670/3750 [00:44<00:00, 81.78it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3671/3750 [00:44<00:00, 81.79it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3672/3750 [00:44<00:00, 81.80it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3673/3750 [00:44<00:00, 81.81it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3674/3750 [00:44<00:00, 81.83it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3675/3750 [00:44<00:00, 81.84it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3676/3750 [00:44<00:00, 81.85it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3677/3750 [00:44<00:00, 81.86it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3678/3750 [00:44<00:00, 81.88it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3679/3750 [00:44<00:00, 81.89it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3680/3750 [00:44<00:00, 81.90it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3681/3750 [00:44<00:00, 81.92it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3682/3750 [00:44<00:00, 81.93it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3683/3750 [00:44<00:00, 81.94it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3684/3750 [00:44<00:00, 81.95it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3685/3750 [00:44<00:00, 81.96it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3686/3750 [00:44<00:00, 81.97it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3687/3750 [00:44<00:00, 81.98it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3688/3750 [00:44<00:00, 82.00it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3689/3750 [00:44<00:00, 82.01it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3690/3750 [00:44<00:00, 82.02it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3691/3750 [00:44<00:00, 82.03it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3692/3750 [00:44<00:00, 82.05it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3693/3750 [00:45<00:00, 82.06it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 3694/3750 [00:45<00:00, 82.07it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 3695/3750 [00:45<00:00, 82.08it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 3696/3750 [00:45<00:00, 82.10it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 3697/3750 [00:45<00:00, 82.11it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 3698/3750 [00:45<00:00, 82.12it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 3699/3750 [00:45<00:00, 82.13it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 3700/3750 [00:45<00:00, 82.15it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 3701/3750 [00:45<00:00, 82.16it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 3702/3750 [00:45<00:00, 82.17it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 3703/3750 [00:45<00:00, 82.18it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3704/3750 [00:45<00:00, 82.19it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3705/3750 [00:45<00:00, 82.21it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3706/3750 [00:45<00:00, 82.22it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3707/3750 [00:45<00:00, 82.23it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3708/3750 [00:45<00:00, 82.24it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3709/3750 [00:45<00:00, 82.25it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3710/3750 [00:45<00:00, 82.27it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3711/3750 [00:45<00:00, 82.28it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3712/3750 [00:45<00:00, 82.29it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3713/3750 [00:45<00:00, 82.30it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3714/3750 [00:45<00:00, 82.31it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3715/3750 [00:45<00:00, 82.33it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3716/3750 [00:45<00:00, 82.34it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3717/3750 [00:45<00:00, 82.35it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3718/3750 [00:45<00:00, 82.36it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3719/3750 [00:45<00:00, 82.38it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3720/3750 [00:45<00:00, 82.39it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3721/3750 [00:45<00:00, 82.40it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3722/3750 [00:45<00:00, 82.41it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3723/3750 [00:45<00:00, 82.43it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3724/3750 [00:45<00:00, 82.44it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3725/3750 [00:45<00:00, 82.45it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3726/3750 [00:45<00:00, 82.46it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3727/3750 [00:45<00:00, 82.48it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3728/3750 [00:45<00:00, 82.49it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3729/3750 [00:45<00:00, 82.50it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3730/3750 [00:45<00:00, 82.51it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 3731/3750 [00:45<00:00, 82.53it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 3732/3750 [00:45<00:00, 82.54it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 3733/3750 [00:45<00:00, 82.55it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 3734/3750 [00:45<00:00, 82.56it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 3735/3750 [00:45<00:00, 82.58it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████▉| 3736/3750 [00:45<00:00, 82.59it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 3737/3750 [00:45<00:00, 82.60it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 3738/3750 [00:45<00:00, 82.61it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 3739/3750 [00:45<00:00, 82.63it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 3740/3750 [00:45<00:00, 82.64it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 3741/3750 [00:45<00:00, 82.65it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 3742/3750 [00:45<00:00, 82.66it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 3743/3750 [00:45<00:00, 82.68it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 3744/3750 [00:45<00:00, 82.69it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 3745/3750 [00:45<00:00, 82.70it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 3746/3750 [00:45<00:00, 82.71it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 3747/3750 [00:45<00:00, 82.73it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 3748/3750 [00:45<00:00, 82.74it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 3749/3750 [00:45<00:00, 82.75it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.641]\u001b[A\n",
      "Epoch 1: 100%|██████████| 3750/3750 [00:45<00:00, 82.74it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.545]\u001b[A\n",
      "Epoch 1: 100%|██████████| 3750/3750 [00:45<00:00, 82.67it/s, loss=0.562, v_num=1, acc=0.812, val_loss=0.545]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkout the directory `lightning_logs`. For each run there is a new directory `version_xx` created. The rightmost argument in the progress bar, the `v_num` variable above shows the version of the current run. Each directory automatically contains a folder with checkpoints, logs and the hyperparameters for this run.\n",
    "\n",
    "As seen in the last notebook, you can have a look at the  logs of the runs in the TensorBoard  \n",
    "Use the command as in the previous notebook in your terminal \n",
    "```\n",
    "tensorboard --logdir lightning_logs\n",
    "```\n",
    "Make sure to use the above command as the same directory as `exercise_07`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using Google Colab, run the following cell to load the TensorBoard extension within the notebook. You may have to scroll to this block whenever you need to look at the TensorBoard interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Add images to tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensorboard logger is a submodule of the `LightningModule` and can be accessed via `self.logger`. We can  add images  to the logging module by calling \n",
    "```python\n",
    "self.logger.experiment.add_image('tag', image)\n",
    "```\n",
    "to add an image. \n",
    "\n",
    "\n",
    "We will log the first batch of validation images in a grid together with the predicted class labels and the ground truth labels. \n",
    "\n",
    "```python\n",
    "        if batch_idx == 0:\n",
    "            self.visualize_predictions(images, out.detach(), targets)\n",
    "```\n",
    "\n",
    "Let's have a look at the implementation of `visualize_predictions()` function in `exercise_code.lightning_models`.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "    def visualize_predictions(self, images, preds, targets):\n",
    "        class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "                       'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "        # determine size of the grid based on given batch size\n",
    "        num_rows = torch.tensor(len(images)).float().sqrt().floor()\n",
    "        \n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        for i in range(len(images)):\n",
    "            plt.subplot(num_rows ,len(images) // num_rows + 1, i+1)\n",
    "            plt.imshow(images[i].permute(1, 2, 0))\n",
    "            plt.title(class_names[torch.argmax(preds, axis=-1)[i]] + f'\\n[{class_names[targets[i]]}]')\n",
    "            plt.axis('off')\n",
    "\n",
    "        self.logger.experiment.add_figure('predictions', fig, global_step=self.global_step)\n",
    "```\n",
    "\n",
    "You can view the logged images in your `IMAGES` tab of TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now looked at how to train a model using PyTorch Lightning. PyTorch Lightning is very active in developement and the features set are continously expanded and updated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Other Features of PyTorch Lightning\n",
    "\n",
    "\n",
    "### Checking  training timings\n",
    "\n",
    "The argument `profiler` of the `Trainer` class measures the time taken in different steps such as dataloading, forward and backward pass. You can select a variety of loggers [here](https://pytorch-lightning.readthedocs.io/en/stable/advanced/profiler.html).\n",
    "\n",
    "Run the cell below to see for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 407 K \n",
      "-------------------------------------\n",
      "407 K     Trainable params\n",
      "0         Non-trainable params\n",
      "407 K     Total params\n",
      "1.628     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  83%|█████████████████████▋    | 3125/3750 [00:18<00:03, 165.28it/s, loss=0.53, v_num=2, acc=0.812]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                      | 0/625 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  83%|█████████████████████▋    | 3126/3750 [00:20<00:04, 155.84it/s, loss=0.53, v_num=2, acc=0.812]\u001b[A\n",
      "Epoch 0:  83%|█████████████████████▋    | 3127/3750 [00:22<00:04, 140.97it/s, loss=0.53, v_num=2, acc=0.812]\u001b[A\n",
      "Epoch 0:  83%|█████████████████████▋    | 3128/3750 [00:22<00:04, 136.89it/s, loss=0.53, v_num=2, acc=0.812]\u001b[A\n",
      "Epoch 0:  83%|█████████████████████▋    | 3129/3750 [00:23<00:04, 135.51it/s, loss=0.53, v_num=2, acc=0.812]\u001b[A\n",
      "Epoch 0:  83%|█████████████████████▋    | 3130/3750 [00:23<00:04, 134.09it/s, loss=0.53, v_num=2, acc=0.812]\u001b[A\n",
      "Epoch 0:  83%|█████████████████████▋    | 3131/3750 [00:23<00:04, 132.78it/s, loss=0.53, v_num=2, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████▋    | 3132/3750 [00:23<00:04, 131.46it/s, loss=0.53, v_num=2, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████▋    | 3133/3750 [00:24<00:04, 130.26it/s, loss=0.53, v_num=2, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████▋    | 3134/3750 [00:25<00:04, 123.94it/s, loss=0.53, v_num=2, acc=0.812]\u001b[A\n",
      "Epoch 0:  84%|██████████████████████▌    | 3135/3750 [00:50<00:09, 61.85it/s, loss=0.53, v_num=2, acc=0.812]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    profiler='simple',\n",
    "    max_epochs=1,\n",
    "    accelerator=\"auto\"\n",
    ")\n",
    "\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see an overview of the time taken for different steps.\n",
    "This  enables us to detect bottlenecks in the model more easily. A bottleneck can be, for example, long times in dataloading. It becomes very important later, especially, when you start to implement custom layers or loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more debugging Options\n",
    "\n",
    "* [`fast_dev_run`](https://pytorch-lightning.readthedocs.io/en/latest/trainer.html#fast-dev-run): Runs of batch of each train, validation and test pass (if validation and test datalaoders are passed as arguments).This is a fast way to check if everything works (dataloading, validation metric, model saving/ loading) without having to wait for a full epoch.\n",
    "\n",
    "* [`track_grad_norm`](https://pytorch-lightning.readthedocs.io/en/latest/trainer.html#track-grad-norm): Logs the  norm of the gradients (set to `1` for the $L1$ norm or `2` for the $L2$ norm) for each layer. You can check whether the network is actually doing something. If the gradients are too small or too high, you won't have a good training (due to vanishing/ exploding gradients).\n",
    "\n",
    "\n",
    "### Other Features\n",
    "\n",
    "Finally, we want to mention some other useful options in the Trainer class:\n",
    "\n",
    "* [`resume_from_checkpoint`](https://pytorch-lightning.readthedocs.io/en/latest/trainer.html#resume-from-checkpoint): Start the training from a checkpoint saved earlier. Argument is the path to the saved model file.\n",
    "* [`Callbacks`](https://pytorch-lightning.readthedocs.io/en/latest/callbacks.html#callback): Callbacks are extremely useful system during training that automate non essential code such as  storing model checkpoints , saving weights values among others.\n",
    "\n",
    "Let's have the look at the [`EarlyStopping`](https://pytorch-lightning.readthedocs.io/en/latest/early_stopping.html#early-stopping-based-on-metric-using-the-earlystopping-callback)  callback.\n",
    "\n",
    "It interrupts the training if the `monitor` metric variable does not  improve for `patience` number of epochs.\n",
    "\n",
    "Below is a code example on how to apply it!\n",
    "\n",
    "```python\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_accuracy',\n",
    "   patience=3,\n",
    "   verbose=False,\n",
    "   mode='max'\n",
    ")\n",
    "\n",
    "trainer = Trainer(max_epochs=10,callbacks=[early_stop_callback])\n",
    "```\n",
    "\n",
    "Your journey with pytorch lightning will force you to check out a bunch of callbacks to return the desired functions without having to write the respective code yourself. Or you hack it in, do as you wish :)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. PyTorch Lightining [`Source Code`](https://github.com/PyTorchLightning/pytorch-lightning) with a nice introduction \n",
    "2. PyTorch Lightining [`Documentation`](https://pytorch-lightning.readthedocs.io/en/latest/#)  Explore it! The features are very well explained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "322ad45fa68ebe5c4128075a6824acd1cfa71405c5d47c425d606c0b05091c60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
